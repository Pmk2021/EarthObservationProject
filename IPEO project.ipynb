{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efdf3917",
   "metadata": {},
   "source": [
    "# IPEO Project: Hurricane Damage Detection with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39afe97e",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f0bd8",
   "metadata": {},
   "source": [
    "### 1.1 Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q torch torchvision matplotlib tqdm gdown "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a8f7ca",
   "metadata": {},
   "source": [
    "### 1.2 Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ec48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252e2d2",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eadb56",
   "metadata": {},
   "source": [
    "Data is already downloaded and stored in local IPEO folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4380e3-a644-43b5-8878-3dc7f6b9ca5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip ipeo_hurricane_damage.zip -d ipeo_hurricane_for_students # Use only one time to unzip data, I now have it downloaded locally and on the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1172d47e",
   "metadata": {},
   "source": [
    "### 2.1 Write a PyTorch Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Hurricane dataset, so that it is not on the __main__\n",
    "from dataset import Hurricane, PoissonNoise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e201d",
   "metadata": {},
   "source": [
    "Look at a random sample to understand what the pictures look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0588594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "dataset = Hurricane(\n",
    "    root_dir=\"ipeo_hurricane_for_students\", # Change this path if needed\n",
    "    split=\"train\",\n",
    "    transforms=None\n",
    ")\n",
    "\n",
    "print(len(dataset))        # should be >0\n",
    "print(dataset.data[:5])    # should show tuples (image_path, label)\n",
    "\n",
    "@interact(idx=range(len(dataset)))\n",
    "def plot_sample(idx=10000):\n",
    "    img, label = dataset[idx]\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b69755",
   "metadata": {},
   "source": [
    "### 2.2 Define transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd4eabc",
   "metadata": {},
   "source": [
    "First, I calculate the mean and standard deviation of my test data to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fc61d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "import numpy as np\n",
    "\n",
    "# Temporary transform to load images as tensors (no normalization!)\n",
    "to_tensor = v2.ToTensor()\n",
    "\n",
    "def compute_mean_std(dataset, batch_size=32):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    n_pixels = 0\n",
    "    mean_sum = torch.zeros(3)\n",
    "    std_sum = torch.zeros(3)\n",
    "\n",
    "    for images, _ in loader: \n",
    "        imgs = images\n",
    "\n",
    "        n_pixels += imgs.numel() / 3  # total per channel\n",
    "        mean_sum += imgs.sum(dim=[0,2,3])\n",
    "        std_sum += (imgs ** 2).sum(dim=[0,2,3])\n",
    "\n",
    "    mean = mean_sum / n_pixels\n",
    "    std = torch.sqrt(std_sum / n_pixels - mean**2)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "# Now I calculate the mean and std of the training dataset\n",
    "\n",
    "train_dataset_noaug = Hurricane(\n",
    "    root_dir=\"ipeo_hurricane_for_students\",\n",
    "    split=\"train\",\n",
    "    transforms=to_tensor     # only convert to tensor\n",
    ")\n",
    "\n",
    "mean, std = compute_mean_std(train_dataset_noaug)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c912281-00e9-4180-bd9f-31f480791fff",
   "metadata": {},
   "source": [
    "I now implement transformations to the training data for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb19f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "import numpy as np\n",
    "\n",
    "# mean and standard deviation of the dataset\n",
    "mean= torch.tensor([0.3518, 0.3832, 0.2849])\n",
    "std= torch.tensor([0.1439, 0.1243, 0.1257])\n",
    "    \n",
    "# normalize image [0-1] (or 0-255) to zero-mean unit standard deviation\n",
    "normalize = v2.Normalize(mean, std)\n",
    "\n",
    "# Normalize for ResNet model\n",
    "normalize_resnet = transforms.Normalize([0.485,0.456,0.406],                   # ImageNet Normalization\n",
    "                                        [0.229,0.224,0.225])\n",
    "\n",
    "    \n",
    "\n",
    "# I invert normalization for plotting later\n",
    "std_inv = 1 / (std + 1e-7)\n",
    "unnormalize = v2.Normalize(-mean * std_inv, std_inv)\n",
    "\n",
    "transforms_train = v2.Compose([\n",
    "  v2.RandomResizedCrop((200, 200)),\n",
    "  v2.RandomGrayscale(),\n",
    "  v2.RandomHorizontalFlip(),\n",
    "  v2.RandomVerticalFlip(),\n",
    "  v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "  v2.RandomPosterize(bits=2),\n",
    "  v2.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "  v2.Resize((224, 224)),\n",
    "  v2.ToTensor(),\n",
    "  PoissonNoise(lam=30.0), \n",
    "  normalize\n",
    "])\n",
    "\n",
    "# I do not augment the validation dataset (aside from resizing and tensor casting)\n",
    "transforms_val = v2.Compose([\n",
    "  v2.Resize((224, 224)),\n",
    "  v2.ToTensor(),\n",
    "  normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0acc1-fbbf-4909-8ada-64ced64b7130",
   "metadata": {},
   "source": [
    "I now visualize the data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df1802-4033-4dc2-bdaf-cce07af391bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_index = 500\n",
    "\n",
    "img, label = dataset[dataset_index]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(12,6))\n",
    "axs[0].imshow(unnormalize(transforms_val(img)).permute(1,2,0))\n",
    "axs[0].set_title(\"validation transform (no augmentation)\")\n",
    "\n",
    "axs[1].imshow(unnormalize(transforms_train(img)).permute(1,2,0))\n",
    "axs[1].set_title(\"training transform\")\n",
    "[ax.axis(\"off\") for ax in axs] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e986c5f0-8f73-482b-93c8-be130738e90c",
   "metadata": {},
   "source": [
    "I now add the transform function to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb45244c-d631-4529-b802-0268914614f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Hurricane(root_dir=\"ipeo_hurricane_for_students\",  split=\"train\", transforms=transforms_train)\n",
    "val_dataset = Hurricane(root_dir=\"ipeo_hurricane_for_students\", split= 'validation', transforms=transforms_val)\n",
    "test_dataset = Hurricane(root_dir=\"ipeo_hurricane_for_students\", split= 'test', transforms=transforms_val)\n",
    "\n",
    "# Visualization\n",
    "fig, axs = plt.subplots(1,5, figsize=(5*3, 3))\n",
    "for ax in axs:\n",
    "    idx = np.random.randint(len(train_dataset)) # random sample\n",
    "    image, label = train_dataset[idx]\n",
    "    ax.imshow(unnormalize(image).permute(1,2,0))\n",
    "    ax.set_title(f\"idx {idx}, {list(Hurricane.LABEL_CLASSES.keys())[label]}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"training samples\")\n",
    "plt.tight_layout()\n",
    "\n",
    "fig, axs = plt.subplots(1,5, figsize=(5*3, 3))\n",
    "for ax in axs:\n",
    "    idx = np.random.randint(len(val_dataset)) # random sample\n",
    "    image, label = val_dataset[idx]\n",
    "    ax.imshow(unnormalize(image).permute(1,2,0))\n",
    "    ax.set_title(f\"idx {idx}, {list(Hurricane.LABEL_CLASSES.keys())[label]}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"validation samples\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a8b08-cf24-4a6b-9f30-6c9e1878ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----------DataLoader creation---------\n",
    "\n",
    "### Compute class weights for balanced sampling\n",
    "train_labels = [label for _, label in train_dataset.data]\n",
    "\n",
    "class_counts = torch.bincount(torch.tensor(train_labels))               # Count number of samples per class, here [1300, 6000]\n",
    "class_weights = 1.0 / class_counts                                      # Inverse frequency, here [1/1300, 1/6000]\n",
    "sample_weights = [class_weights[label] for label in train_labels]       # Assign weight to each sample based on its class\n",
    "\n",
    "# Test if the weights are correct\n",
    "# contribution totale par classe\n",
    "total_weight_class0 = class_weights[0] * class_counts[0]\n",
    "total_weight_class1 = class_weights[1] * class_counts[1]\n",
    "\n",
    "total = total_weight_class0 + total_weight_class1\n",
    "\n",
    "print(\"Sampling probabilities (true):\")\n",
    "print(\"damage (0)    →\", (total_weight_class0 / total).item())\n",
    "print(\"no_damage (1) →\", (total_weight_class1 / total).item())\n",
    "\n",
    "# The train batch are now sampled equally from all classes\n",
    "# Each bach has the same number of samples from each class on average\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "### 4. Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=False # only false on macos\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=False # only false on macos\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=False # only false on macos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ----------ResNet 18----------\n",
    "# Import\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "\n",
    "\n",
    "# Function to build a ResNet model with a custom number of output classes\n",
    "def build_resnet(num_classes=2, pretrained=True):\n",
    "    \"\"\"\n",
    "    ResNet18 extracts generic visual features\n",
    "    we only replace the classification head (last layer)\n",
    "    the network learns to distinguish damage / no_damage\n",
    "    \"\"\"\n",
    "\n",
    "    model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "    # Replace the last fully connected layer\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = build_resnet(num_classes=2, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "logits = model(images)\n",
    "\n",
    "print(\"Logits shape:\", logits.shape) # Expected output:Logits shape: torch.Size([32, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "# Using AdamW optimizer, which is well-suited for training deep learning models and stable with resnet\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "\n",
    "# ----------Training loop----------\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "\n",
    "    return running_loss / len(loader.dataset), acc, f1\n",
    "\n",
    "\n",
    "# ----------Validation loop----------\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(targets.cpu())\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds)\n",
    "\n",
    "    return running_loss / len(loader.dataset), acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e659c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Main training loop----------\n",
    "num_epochs = 10\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(\n",
    "        model, train_loader, optimizer, criterion, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_f1 = evaluate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train → loss={train_loss:.4f}, acc={train_acc:.4f}, f1={train_f1:.4f}\")\n",
    "    print(f\"Val   → loss={val_loss:.4f}, acc={val_acc:.4f}, f1={val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), \"best_resnet18.pt\")\n",
    "        print(\"Best model saved\")\n",
    "\n",
    "# ----------Testing loop----------\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_resnet18.pt\"))\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_f1 = evaluate(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "# Print test results\n",
    "print(f\"\\nTEST → loss={test_loss:.4f}, acc={test_acc:.4f}, f1={test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a7026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
